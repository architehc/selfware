# Selfware configuration
# Copy this file to selfware.toml and adjust values for your setup.

# Set this to your OpenAI-compatible API endpoint (e.g., local vLLM/sglang server, ngrok tunnel, etc.)
endpoint = "http://localhost:8080/v1"
model = "your-model-name-here"
max_tokens = 98304

[safety]
allowed_paths = ["./**", "~/**"]
denied_paths = ["**/.env", "**/secrets/**", "**/.ssh/**", "**/target/**"]

[agent]
max_iterations = 500
step_timeout_secs = 600
# Enable native function calling (requires backend support like sglang --tool-call-parser)
native_function_calling = true

[continuous_work]
enabled = true
checkpoint_interval_tools = 10
checkpoint_interval_secs = 300
auto_recovery = true
max_recovery_attempts = 3

[retry]
max_retries = 5
base_delay_ms = 1000
max_delay_ms = 60000
